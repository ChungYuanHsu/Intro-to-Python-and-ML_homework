{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=1978DD> HWQ: use RNN to analyze movie reviews</font> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: KERAS_BACKEND=tensorflow\n",
      "訓練集資料量: 25000\n",
      "測試集資料量: 25000\n"
     ]
    }
   ],
   "source": [
    "%env KERAS_BACKEND=tensorflow\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.datasets import imdb\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "print('訓練集資料量:', len(x_train))\n",
    "print('測試集資料量:', len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=FC8600>  maxlen=300</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 300)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = sequence.pad_sequences(x_train, maxlen=300)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=300)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=FC8600>  N-dimension and number of LSTM</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 300 # N-dimension\n",
    "K = 40 # number of LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=FC8600> add Dropout function (reduce overfitting) </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_26 (Embedding)     (None, None, 300)         3000000   \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, None, 300)         0         \n",
      "_________________________________________________________________\n",
      "lstm_26 (LSTM)               (None, 40)                54560     \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 3,054,601\n",
      "Trainable params: 3,054,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(10000, N))\n",
    "model.add(Dropout(0.35))\n",
    "model.add(LSTM(K))\n",
    "model.add(Dropout(0.35))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer=Adam(),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=FC8600> batch_size=100 and add validation_data</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 200s 8ms/step - loss: 0.4278 - acc: 0.8001 - val_loss: 0.3078 - val_acc: 0.8669\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 198s 8ms/step - loss: 0.2344 - acc: 0.9098 - val_loss: 0.3094 - val_acc: 0.8701\n"
     ]
    }
   ],
   "source": [
    "model_his = model.fit(x_train, y_train,\n",
    "            batch_size=100,\n",
    "            epochs=2,\n",
    "            validation_data = (x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 38s 2ms/step\n",
      "testing data loss=0.3094479087257385\n",
      "testing data accuracy:0.87008\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)\n",
    "print(f'testing data loss={score[0]}')\n",
    "print(f'testing data accuracy:{score[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=FC8600> conclusion </font> \n",
    "### <font color=(0,0,0)> 這次調參數的過程相當tricky,由於擷取的數據隨機性相當高，<br /> 加上overfitting問題嚴重，因此到達一定準確率之後要再提升不容易。</font> \n",
    "### <font color=(0,0,0)> 最後產生的準確率是<font color=FC0505>87.008%  </font> 勉強達標。</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=FC8600> 查詢資料後整理關於 \"overfitting\"常見的處理方法 </font> \n",
    "https://ithelp.ithome.com.tw/articles/10203371"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=0349F7> 1. Dropout </font> \n",
    "### <font color=020713>  $\\;\\;\\;\\;$ 減少神經網絡的層數、神經元個數等方式可以限制神經網絡的擬合能力，隨機關閉一些神經元<br />  $\\;\\;\\;\\;$ 以減少過擬合的情況</font>\n",
    "### <font color=0349F7>  2. Early Stopping </font>\n",
    "### <font color=020713>  $\\;\\;\\;\\;$ 在每一個 epoch 結束時計算驗證集（validation data）的準確率，當準確率不再提高就停止訓練。<br />  $\\;\\;\\;\\;$ 這是一個很常用的方法，好處是解決手動設置 epoch 數的問題（節省訓練模型時間），還能防止 overfitting。    </font>\n",
    "### <font color=0349F7> 3. Weight Decay </font> \n",
    "### <font color=020713>  $\\;\\;\\;\\;$ 原理是在 cost function 的後面增加一個懲罰項（代表對某些參數做一些限制），如果一個權重太大，<br />  $\\;\\;\\;\\;$ 將導致代價過大，因此在反向傳播後就會對該權重進行懲罰，使其保持在一個較小的值。    </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
